*By:Laura Cunha Silva - VPHI*

##December 2022 /January 2023##

*Import working dataset = dataset without the predictions*

```{r}
library(dplyr)
library(lubridate)
library(leaflet)
library(readxl)
library(ggplot2)
library(viridis)
library(hrbrthemes)
library(rio)

#Add Saskia's df 
#setwd("G:/VPHI//Epi/Projects/100_PigNetworkModeling_SNF (Duerr)/DatasetsAnalysis/Tour_prediction/Laura")
setwd("G:/Epi/Projects/100_PigNetworkModeling_SNF (Duerr)/DatasetsAnalysis/Tour_prediction/Laura")#work pc 

#tvd_data <- import("G:/VPHI/Epi/Projects/100_PigNetworkModeling_SNF (Duerr)/DatasetsAnalysis/Tour_prediction/Laura/TVD_with_tourid.csv")
tvd_data <- import("G:/Epi/Projects/100_PigNetworkModeling_SNF (Duerr)/DatasetsAnalysis/Tour_prediction/Laura/TVD_with_tourid.csv")#work pc 

#Save a copy of the original dataset 
tvd_data_original <- tvd_data #backup

length(unique(tvd_data_original$v1))
length(unique(tvd_data_original$tourid))

```

*Dataset basic cleaning & description*

```{r}
ls(tvd_data)
#Only keep the variables of importance 
tvd_data <- tvd_data %>%
  select(year,day_of_year,tourid,tvd_source,tvd_dest,prod_type_source,prod_type_dest,notif_type,latid_est,longid_est,latis_est,longis_est,n_pigs,c_plannedarrivaltime,c_plannedarrivaltimeablad)

#Select only year 2019
tvd_data$year <- as.factor(tvd_data$year)
summary(as.factor(tvd_data$year)) 

tvd_data <- tvd_data %>% 
  filter(year == "2019")

ls(tvd_data)

#Rename the variables so that they match the ones we had in the previous dataset 

length(unique(tvd_data$tourid))#There are a total of 107012 tours made in the year 2019

#THERE ARE 23695 export/import happening throughout the year 2019 
length(unique(tvd_data$tvd_source)) #9387 different farms are source farms (sending farms)
length(unique(tvd_data$tvd_dest)) #5931 are destination farms (receiving farms)
length(unique(tvd_data$day_of_year)) #365 days

summary(as.factor(tvd_data$prod_type_source)) 

summary(as.factor(tvd_data$prod_type_dest)) 

summary(as.factor(tvd_data$notif_type))




```

###Information on the dataset###

*note well (translations) : *
AFP = piglet production ring 
Mast = Fattener
Zucht = Breeder
Schlacht_gr = Big slaughterhouse 
Schlacht_kl = Small slaughterhouse 
Vermhr = multiplier herd 
Unk = Unknown

IMPORTANT TO DO: Kern = nucleous herds need to be separated from the other farms since they have the highest SGD status 
*PRODUCTION TYPE:*
"Kern" ~ 1
"Vermhr" ~2
"Züchter" (Breeder) ~3, 
"Ferkelaufzüchter" (Piglet raiser) =  here is labeled as "AFP" ~ 4,             
"Mäster" (Fatteners) | (Unk & notif_type=1) ~5,
Slaughterhouses ~6

*Notification types:*
1= farm to farm 
2= farm to slaughterhouse 

```{r}
#Separate the kern farms  
#Kern farms are always source farms 

#Create a new variable that groups and classifies according to the SGD status of the farms = remove since it is redundant 
#tvd_data$SGD_status_source = ifelse(tvd_data$farm_type_source%in%"Kern",1,
                           #ifelse(tvd_data$farm_type_source%in%"Vermehr",2,3))

#summary(as.factor(tvd_data$SGD_status_source))
# 1       2      3 
#1050   920    21905 
                                  
#tvd_data$SGD_status_dest = ifelse(tvd_data$farm_type_dest%in%"Kern",1,
                           #ifelse(tvd_data$farm_type_dest%in%"Vermehr",2,3))

#summary(as.factor(tvd_data$SGD_status_dest))
#2     3 
#138  23737   ----> No import/exports from kern to kern 

#Create a new variable that groups and classifies according to the Production type of the farms
tvd_data$production_type_source = ifelse(tvd_data$prod_type_source%in%"Kern",1,
                           ifelse(tvd_data$prod_type_source%in%"Vermehr",2,
                                  ifelse(tvd_data$prod_type_source%in%"Zucht",3,
                                         ifelse(tvd_data$prod_type_source%in%"AFP",4,
                                                ifelse(tvd_data$prod_type_source%in%"Mast" | (tvd_data$prod_type_source%in%"Unk" & tvd_data$notif_type<2),5,6))))) #6 are the slaughterhouses (doesn't matter if big or small)

summary(as.factor(tvd_data$production_type_source)) 
#1     2     3     4     5     6 
# 5334  4727 55506 19802 87326   118  

tvd_data$production_type_dest = ifelse(tvd_data$prod_type_dest%in%"Kern",1,
                           ifelse(tvd_data$prod_type_dest%in%"Vermehr",2,
                                  ifelse(tvd_data$prod_type_dest%in%"Zucht",3,
                                         ifelse(tvd_data$prod_type_dest%in%"AFP",4,
                                                ifelse(tvd_data$prod_type_dest%in%"Mast"|(tvd_data$prod_type_dest%in%"Unk" & tvd_data$notif_type<2),5,6)))))

summary(as.factor(tvd_data$production_type_dest))
#1      2      3      4      5      6 
#1    679   4016   7177  39086 121854 


```

*In order to try to find how many deterministic tours we have in 2019 we must first ID how many tours have more than one transport. Meaning, we will ID the number of tours that only have one transport*


```{r}
#Tidy up the dataset ##
#We have DUPLICATES IN THE DATA (eg tourID T-004876) I also confirmed in the original dataset before any transformations were done that these duplicates are absolute 
#How many? How many times do these duplicates repeat themselves? 
names(tvd_data)

tvd_data <- tvd_data %>% group_by(day_of_year,tourid,tvd_source,tvd_dest,production_type_source,production_type_dest,notif_type,n_pigs,latid_est,longid_est,latis_est,longis_est) %>% 
  mutate(Repeats = row_number()-1)

summary(as.factor(tvd_data$Repeats)) #we have 480 duplicates

#Lets remove the duplicates and the Repeats variable 
tvd_data <- tvd_data %>% 
  filter(Repeats == 0) #eliminate the duplicates 

tvd_data$Repeats <- NULL 

length(unique(tvd_data$tourid))

tvd_data <- tvd_data[,c("day_of_year","tourid","tvd_source","tvd_dest","production_type_source","production_type_dest","notif_type","n_pigs", "latid_est","longid_est","latis_est","longis_est")]

tvd_data <- tvd_data %>% 
  ungroup() %>% 
  group_by(day_of_year,tourid) %>% 
  arrange(day_of_year,tourid)

#######Lets remove the single transport farms from the dataset as they do not require any ordering ######

#How many tours only have one transport (meaning only observation per tour id)? 
singlefarm_tours <- tvd_data %>% 
  group_by(day_of_year,tourid) %>% 
  dplyr::mutate(num_dups = n()) %>% #tells you how many times that particular combo is duplicated = how many tours only have one observation = tours with only one transport
  filter(num_dups == "1") %>%
  ungroup() %>% 
  arrange(day_of_year,tourid,production_type_source,production_type_dest)

length(unique(singlefarm_tours$tourid))#We have 81118 single transport tours ~ 75.80% of all tours only do one transport 

#How many of these transports are in between farms and how many are from a farm directly to the slaughterhouse?
singlefarm_tours_farmtofarm <- singlefarm_tours %>% 
  filter(notif_type == "1") %>%
  arrange(day_of_year,tourid,production_type_source,production_type_dest)

length(unique(singlefarm_tours_farmtofarm$tourid)) #22120 tours with just one transport are in between two different farms ~  27.27% of all single tours are single transport between two farms 

singlefarm_tours_slaughter <- singlefarm_tours %>% 
  filter(notif_type == "2") %>%
  arrange(day_of_year,tourid,production_type_source,production_type_dest)

length(unique(singlefarm_tours_slaughter$tourid)) #58998 tours with just one transport are in between two different farms ~  72.73% of all single tours are from one farm to the slaughterhouse

#########################################################################################################
tvd_data <- tvd_data %>% 
  group_by(day_of_year,tourid) %>% 
  arrange(day_of_year,tourid)
```

```{r}
#Check the basics for each tour = min, maximum, average of the transports per tour 
n <- tvd_data %>% 
  group_by(day_of_year,tourid) %>%
  tally()

summary(n$n)

#Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
#1.00    1.00    1.00    1.61    1.00   23.00

#There are two tours that have 23 transports 
#P-00020199 and P-00030836


```
*Explore the tours with more than one transport* 

```{r}
#Lets remove the single tour farms from the dataset
work_data <- tvd_data %>% 
  group_by(day_of_year,tourid) %>% 
  dplyr::mutate(num_dups = n()) %>% #tells you how many times that particular combo is duplicated = how many tours only have one observation = tours with only one transport
  filter(num_dups > "1") %>%
  ungroup() %>% 
  arrange(day_of_year,tourid)

#How many tours require work (deterministic tours + complex)? 
length(unique(work_data$tourid)) #25894 tours ~ 24.20% of all tours are not single transport tours 

work_data_original <- work_data

```
*Let's identify each tour's destination so this info is not lost and we modify further the dataset* 

```{r}
work_data <-  work_data %>% 
  group_by(day_of_year,tourid,tvd_dest) %>% #because we know that sometimes the dest is the same to several sources 
  mutate(destination = tvd_dest)

work_data <- work_data %>% 
  ungroup()

work_data <- work_data %>% 
  group_by(day_of_year,tourid)
```

*Examine whether we have destinations with the same or higher status than the sources* 
```{r}
val_destsource <- work_data %>% group_by(day_of_year,tourid, destination) %>% 
  filter(production_type_source > production_type_dest) #343 sources have higher status than destinations 

val_destsource2 <- work_data %>% group_by(day_of_year,tourid,destination) %>% 
  filter(production_type_source == production_type_dest) #5257 sources have the same status than destinations 

```

*Let's order the work data = all tours with more than one transport, according to the time of their visit* 

```{r}
#We need to change the way our dataset is organized since we are not interested in the listed destination and sources, we want to determine the sequence of the visits # 
tvd_destinations <- work_data %>% 
  select(day_of_year,tourid,tvd_dest,destination,production_type_dest,longid_est,latid_est,n_pigs,notif_type)

tvd_destinations$class <- "destination"

tvd_destinations <- rename(tvd_destinations, TVD=tvd_dest)
tvd_destinations <- rename(tvd_destinations, production_type=production_type_dest)
tvd_destinations <- rename(tvd_destinations, longitude=longid_est)
tvd_destinations <- rename(tvd_destinations, latitude=latid_est)

tvd_sources <- work_data %>% 
  select(day_of_year,tourid,tvd_source,destination,production_type_source,longis_est,latis_est,n_pigs,notif_type)

tvd_sources$class <- "source"

tvd_sources <- rename(tvd_sources, TVD=tvd_source)
tvd_sources <- rename(tvd_sources, production_type=production_type_source)
tvd_sources <- rename(tvd_sources, longitude=longis_est)
tvd_sources <- rename(tvd_sources, latitude=latis_est)

work_tvd_data <-  rbind(tvd_destinations,tvd_sources)

work_tvd_data <- work_tvd_data %>% 
  group_by(day_of_year,tourid) %>% 
  arrange(day_of_year,tourid)

#We have duplicates which is expected = they come from the original dataset where we had previously noted that we had transports that shared destinations and sources. Lets remove these duplicates as they are unnecessary 
work_tvd_data <- work_tvd_data %>% group_by(day_of_year,tourid,TVD,production_type,notif_type,n_pigs,latitude,longitude,class) %>% #dist_km is not considered since it no longer applies
  mutate(Repeats = row_number()-1)

summary(as.factor(work_tvd_data$Repeats)) #we have 7988 duplicates

#Lets remove the duplicates and the Repeats variable 

work_tvd_data <- work_tvd_data %>% 
  filter(Repeats == 0) #eliminate the duplicates 

work_tvd_data$Repeats <- NULL 

length(unique(work_tvd_data$tourid))

```


```{r}
work_tvd_data2 <- work_tvd_data #backup

work_tvd_data$farm_status <- work_tvd_data$production_type

work_tvd_data<- work_tvd_data %>% 
  ungroup() %>% 
  group_by(day_of_year,tourid) %>% 
  arrange(day_of_year,tourid,farm_status) 

```
*How many of our workable tours are deterministic = can be defined solely with the status of visiting farms*

```{r}
working_data <- work_tvd_data %>% 
  ungroup() %>%
  select(day_of_year,tourid,TVD, farm_status,destination,longitude,latitude,n_pigs,class) %>%
  group_by(day_of_year,tourid)

working_data <- working_data %>% ungroup() %>% group_by(day_of_year,tourid,TVD,farm_status) %>% mutate(dupes_TVD = n()) 
summary(working_data$dupes_TVD)

#Remove deterministic tours = those that have no dupes ####

working_data<- working_data %>% 
  ungroup() %>% 
  group_by(day_of_year,tourid) %>% 
  arrange(day_of_year,tourid,farm_status) %>% 
  mutate(sequence_status_unbiased = row_number()) 
  
working_data <- working_data%>%
  group_by(tourid,farm_status) %>% mutate(across(starts_with('sequence_status_unbiased'), ~min(.))) #we now have a variable that details the last farm visited, the farms competing for the same positions in the tour 

working_data <- working_data%>%
  group_by(day_of_year,tourid,class) %>% 
  arrange(day_of_year,tourid,farm_status) %>% 
  mutate(sequence_status_class = row_number())

working_data <- working_data%>%
  ungroup() %>% 
  group_by(day_of_year,tourid,TVD) %>% mutate(across(starts_with('sequence_status_class'), ~min(.))) #now we will have the sequence based on the status of the farms and the class (source or destination)

#IDENTIFY THE TOURS THAT ARE DETERMINISTIC ####

working_data <- working_data %>% ungroup() %>% group_by(day_of_year,tourid,TVD,sequence_status_class) %>% mutate(dupes = n())

uniqueSequenceOrder <- sort(unique(working_data$sequence_status_unbiased)) #we know the maximum visited farms in a tour is 23 

working_data$TVD <- as.character(working_data$TVD)

#For filtering sake we will remove the duplicates of destinations and sources# 
working_data_wo_dupes <- working_data %>% 
  group_by(day_of_year,tourid) %>%
  distinct(TVD,.keep_all=TRUE)

determ_tours <- working_data_wo_dupes %>% 
  ungroup() %>% 
  group_by(day_of_year,tourid) %>% #making sure the observations are ordered based on the sequence 
  filter((all(diff(match(sequence_status_unbiased,uniqueSequenceOrder))==1))) %>% 
  arrange(day_of_year,tourid,farm_status)#if the values of the sequence are not consecutive (meaning there are competing farms for tour visiting order) then the tour cannot be ordered solely based on the Farm_status of the integrating farms
#by using the function match we can ignore duplicated observations otherwise the function to identify consequential values wont work (e.g.T-004949). THIS ONLY FILTERS THE TOURS THAT DO NOT HAVE DUPLICATED SOURCES/DESTINATIONS 

length(unique(determ_tours$tourid)) #2719 tours are deterministic = 2.54% of all tours 

#Remove the deterministic tours from the working dataset 
complex_tours <- anti_join(working_data,determ_tours, by = c("tourid" = "tourid"))

length(unique(complex_tours$tourid)) #23175 tours that need more work, aka complex = 21.66% of all tours 


```
Brief notes on the sequences designations: 
sequence_status_unbiased = sequence solely based on the farm_status

sequence_status_class = sequence based solely on the farm_status but also groupped per class (source|destination)


*We have now organized our data into single transport tours, deterministic tours and complex tours. We have been able to subset from the original 2019 tour dataset all the tours asides from the complex tours. We now have some extra work to do on the complex tours in order to determine its sequence* 

```{r}
#Tidy up#### 

complex_tours$dupes <- NULL

complex_tours$Points <- paste(complex_tours$longitude, complex_tours$latitude, sep = " , ")
library(geosphere)

#Again it makes sense to remove duplicates from the complex tours as well. 

complex_tours_backup_with_dupes <- complex_tours

complex_tours <- complex_tours %>%
  group_by(day_of_year,tourid) %>%
  distinct(TVD,.keep_all=TRUE)

#Therefore let us re_code a dupes_status variable for us to know how many times a certain status repeats 
complex_tours <- complex_tours %>% ungroup() %>% group_by(day_of_year,tourid,farm_status) %>% mutate(dupes_status = n()) 

complex_tours <- complex_tours[,c("day_of_year","tourid","TVD","farm_status","destination","longitude", "latitude","n_pigs","class","sequence_status_unbiased","dupes_status","sequence_status_class","Points","dupes_TVD")] #order variables to make it easier 


#Every time there is a distinct value in sequence_status_unbiased , the min distinct value should be defined as center (independent of being a source or destination)
complex_tours$dupes_status <- as.numeric(complex_tours$dupes_status)
complex_tours$sequence_status_unbiased <- as.numeric(complex_tours$sequence_status_unbiased)

complex_tours <- complex_tours %>% 
  ungroup() %>% 
  group_by(day_of_year,tourid) %>% 
  mutate(centers = case_when(!duplicated(sequence_status_unbiased) & dupes_status==1 ~ Points)) %>%
  mutate(RealCenter = row_number(centers) == 1)#define the center for distance calculation =  non duplicated observations in sequence_status_unbiased but it is not the first one and we need to only have the first non duplicated observation to be considered as center (check e.g. 14757)

complex_tours <- complex_tours %>% 
  group_by(day_of_year,tourid) %>% 
  mutate(center= case_when(!centers=="NA" & RealCenter==TRUE ~ Points))

#Eliminate the extra variables created to determine the correct center for our distance calculations 
complex_tours <- complex_tours %>% select (-c(RealCenter, centers))

#Edges are all that have dupes in dupes_status 
complex_tours <- complex_tours %>% 
  ungroup() %>% 
  group_by(day_of_year,tourid) %>% 
  mutate(edges = case_when(dupes_status>1  ~ Points))

#Calculate distances from the center to the edges####
#Calculate the distance from the center to all the others (edges), per group
library(tidyr)
library(geosphere)
library(sp)

complex_tours <- complex_tours %>% 
  group_by(day_of_year,tourid) %>% 
  mutate(center_lon = case_when(is.na(center)==FALSE ~ longitude)) %>% 
  mutate(center_lat = case_when(is.na(center)==FALSE ~ latitude)) #we extracted the coordinates for each central point 

complex_tours <- complex_tours %>% 
  group_by(day_of_year,tourid) %>% 
  mutate(edges_lon = case_when(is.na(edges)==FALSE ~ longitude)) %>% 
  mutate(edges_lat = case_when(is.na(edges)==FALSE ~ latitude)) #we extracted the coordinates for each edge point

complex_tours <- complex_tours %>% 
  ungroup() %>% 
  group_by(day_of_year,tourid) %>% 
  fill(center,.direction = "down") %>% 
  fill(center,.direction = "up") %>% 
  fill(center_lon,.direction = "down") %>% 
  fill(center_lon,.direction = "up") %>% 
  fill(center_lat,.direction = "down") %>% 
  fill(center_lat,.direction = "up")#this code chunk ensures that the center of each edges is easily identifiable and makes the calculations of distance between center-edges possible 

complex_tours$center_lon[is.na(complex_tours$center_lon)] <- 0
complex_tours$center_lat[is.na(complex_tours$center_lat)] <- 0

complex_tours$edges_lon[is.na(complex_tours$edges_lon)] <- 0
complex_tours$edges_lat[is.na(complex_tours$edges_lat)] <- 0

#Create the datasets with the coordinates for the distance calculations####
#Now I am subsetting the dataset to keep only the visits that have a center to make it easier to calculate the distances 
centeronly <- complex_tours %>%
  group_by(day_of_year,tourid) %>% 
  filter(is.na(center)==FALSE & center_lon>0 & center_lat >0 & edges_lon>0 & edges_lat>0) #we are only keeping the observations that have center and edges and we need to decide the order 

centeronly <- centeronly %>% 
  group_by(day_of_year,tourid) %>%
  filter(center_lon>0 & center_lat >0 & edges_lon>0 & edges_lat>0)

center <- centeronly %>% 
  ungroup() %>% 
  group_by(day_of_year,tourid) %>% #just to make absolutely sure the order is not lost 
  select(center_lon,center_lat)

center$doy<- NULL
center$BeraterNAdr_ID <- NULL

edges <- centeronly%>%
  ungroup() %>% 
  group_by(day_of_year,tourid) %>% #just to make absolutely sure the order is not lost 
  select(edges_lon,edges_lat)

edges$doy<- NULL
edges$BeraterNAdr_ID <- NULL

#Calculate distances 
center$lon <- center$center_lon
center$lat <- center$center_lat

center$center_lon <- NULL
center$center_lat <- NULL

edges$lon <- edges$edges_lon
edges$lat <- edges$edges_lat

edges$edges_lon <- NULL
edges$edges_lat <- NULL

center <- SpatialPoints(center[c("lon", "lat")]) #WGS84
edges <- SpatialPoints(edges[c("lon", "lat")]) #WGS84
  
crs.geo<-CRS("+init=epsg:32632") #info from epsg.io 

proj4string(center) <-crs.geo #define projection
proj4string(edges) <-crs.geo

library(geosphere)
#get the coordinates of gps and centroid 
pointCenters <- center@coords
pointedges<-edges@coords
#prepare a vector which will contain the minimum distance for each gps point
res_cent_edges <-numeric(nrow(pointedges))
#get the min distances
for (i in 1:length(res_cent_edges)) res_cent_edges[i]<- min(distHaversine(pointedges[i,,drop=FALSE],pointCenters)) #distance in meters

length(res_cent_edges)#check that the number of rows in the same as the original dataset
#to add the distances
res_cent_edges <- as.vector(res_cent_edges)
dist_cent_edges <- res_cent_edges
summary(dist_cent_edges)
centeronly$dist_cent_edges <- dist_cent_edges #given in meters

#Need to now bind this column to the original dataframe = complex_tours 
complex_tours$dist_cent_edges <- NA #to rbind later

centeronly <- centeronly %>% 
  group_by(day_of_year,tourid) %>% 
  select(day_of_year, tourid, TVD, dist_cent_edges)

complex_tours <- merge(complex_tours,centeronly , by=c("day_of_year","tourid","TVD"), all=TRUE) # NA's match

complex_tours$dist_cent_edges.x <- NULL

```

```{r}
#Since we have destination farms with the same or higher status than the source farms in the same tour we want to make sure that the sources come before the destinations 
complex_tours <- complex_tours %>% 
  group_by(day_of_year,tourid) %>%
  mutate(classvalue = case_when(class == "source" ~ 1 , 
                                TRUE ~ 2))

#Arrange(farm_status,distance) = so that priority is still given to the status of the farm and only if the status is the same should the distance to the center be considered 

complex_tours <- complex_tours %>% 
  ungroup() %>% 
  group_by(day_of_year,tourid) %>% 
  arrange(day_of_year,tourid,farm_status,classvalue,dist_cent_edges.y)  %>% 
  mutate(sequence_status_dist = row_number())
```


*Let's determine how much compatibility there is between the recorded sequence and the our pre-determined rules that the tours abide by the status of the farms rules + shortest distance* 
```{r}
#Return dataset to its original format (but keeping it on a farm basis format, not transport basis) = merge determ datatset + complex_tours; Single farm tours do not interest us! 

complex_tours_final <- complex_tours#backup

#tidy up the complex tours dataset & determ datatset #### 
complex_tours <- complex_tours %>% select (-c(center_lat, center_lon,edges_lon,edges_lat))

names(complex_tours)
names(determ_tours)

determ_tours$center <- NA 
determ_tours$edges <- NA 
determ_tours$dupes_status <- NA 
determ_tours$dist_cent_edges.y <- NA 
determ_tours$sequence_status_dist <- NA 

complex_tours <- complex_tours %>% 
  ungroup() %>% 
  group_by(day_of_year,tourid) %>% 
  arrange(day_of_year,tourid,farm_status) 

determ_tours <- determ_tours %>% 
  ungroup() %>% 
  group_by(day_of_year,tourid) %>% 
  arrange(day_of_year,tourid,farm_status) 

final1 <- rbind(complex_tours, determ_tours)

#Save as CSV file 
#G:\Epi\Projects\100_PigNetworkModeling_SNF (Duerr)\DatasetsAnalysis\Tour_prediction\Laura\Final_dataset_analysis
##write.csv(final1,"G:\\Epi\\Projects\\100_PigNetworkModeling_SNF (Duerr)\\DatasetsAnalysis\\Tour_prediction\\Laura\\Final_dataset_analysis\\FinalSequences_dataset.csv", row.names = FALSE) #work pc 

```


```{r}
#Total of final tour ID has to be = 2719 + 23175 = 25894  
length(unique(final1$tourid)) #check OK = 25894


#How many matches are there between seq_status and sequence_status_dist
#Final dataset without NA
final <- final1 %>% 
  ungroup() %>% 
  group_by(day_of_year,tourid) %>% 
  arrange(day_of_year,tourid,farm_status,classvalue,dist_cent_edges.y) %>% 
  mutate(sequence_status_dist = row_number())


sum(final$sequence_status_unbiased == final$sequence_status_dist)#68483 = 52.41% of all observations in the dataset

```

```{r}
#Calculate the change in the order of the sequences = WE NO LONGER HAVE SEQUENCE_TIME so I will change it to sequence_status_unbiased 

order <- final %>% 
  group_by(day_of_year,tourid) %>%
  select(day_of_year,tourid,sequence_status_unbiased,sequence_status_dist,TVD,destination,class)

order <- order %>% 
  group_by(day_of_year,tourid) %>% #the final dataset is arranged based on the sequence_status_dist we have to calculate the difference for the sequence_status_unbiased
  mutate(order_diff = sequence_status_unbiased - lag(sequence_status_unbiased))

length(unique(order$tourid)) #6120

#To calculate the percentage of change in the order between the time based sequence and the sequence we created (sequence_status_dist) we have the sum the values in variable order_diff=1 (=the ones that maintained their relative position) and divide by the maximum vale of the sequence 


 
#Want to create a dataset with the TOUR ID + MAX NUMBER OF TRANSPORTS IN THE TOUR + SUM WHEN (ORDER_DIFF==1)    
order_tours  <- aggregate(x = order$sequence_status_dist,                
                    by = list(order$tourid),              
                    FUN = max) #x is the maximum number of transports per tourID 

order$order_diff <- as.numeric(order$order_diff)

f4 <- order %>%
  group_by(tourid) %>%
  rowwise() %>%
  mutate(sums = sum(ifelse(order_diff==1,order_diff, NA))) 

f4 <- f4 %>% 
  group_by(tourid) %>% 
  filter(sums == 1) %>% 
  mutate(total = sum(sums)) #we now have duplicates which we have to remove 

f4 <- f4 %>% 
  group_by(tourid) %>% 
  distinct(day_of_year,tourid,total)

length(unique(order_tours$Group.1))#25894
length(unique(f4$tourid))#13250

#merge f4 with order_tours based on the tourID that have kept at least one of the sequence orders 
order_tours$tourid <- order_tours$Group.1
order_tours$max_transp <- order_tours$x

order_tours$Group.1 <- NULL 
order_tours$x <- NULL

f4$max_transp <- NA
order_tours$day_of_year <- NA
order_tours$total <- NA

f4 <- f4[,c("day_of_year","tourid","max_transp","total")]
order_tours <- order_tours[,c("day_of_year","tourid","max_transp","total")]
 
order_fin <- merge(order_tours,f4, by="tourid")

order_fin$max_transp.y <- NULL 
order_fin$day_of_year.x<- NULL
order_fin$total.x <- NULL

order_fin <- order_fin %>% 
  group_by(tourid) %>% #tourID 
  mutate(n_kept_order =(total.y*100)/(max_transp.x-1)) #total number of transports minus 1 because if we have 23 transports it means we have 22 ordered sequence values even when the sequence is perfect (1-2-3-4 there are only 3 diff to be calculated between the 4 numbers)

mean(order_fin$n_kept_order) #44.54
median(order_fin$n_kept_order) #33.33
max(order_fin$n_kept_order) #100
min(order_fin$n_kept_order) #3.85

#order <- order %>% 
  #group_by(day_of_year,tourid) %>%
  #mutate(total_transports = max(sequence_status_dist))#create a column that is the total number of transports within each tour
  
#order_tour <- order %>% 
  #group_by(day_of_year,tourid) %>%
  #filter(order_diff==1) %>% #only keep the values that are ones
  #mutate(count = sum(order_diff)) %>% #sum the 1 values 
  #mutate(per =  100 *max(count)/ (total_transports-1)) %>% #total number of transports minus 1 because if we have 17 transports it means we have 16 ordered sequence values even when the sequence is perfect (1-2-3-4 there are only 3 diff to be calculated between the 4 numbers)
  #ungroup


#How many tours had a change in their order = meaning the tours that did not have a single 1 (0% match) and the tours that are not 100% matches 

#ALL THE TOURS THAT WENT TO BE PART OF THE F4 HAVE TO HAVE AT LEAST ONE 1 
length(unique(f4$tourid)) #13250 (meaning 100% matches and not perfect matches)

25894 - 13250 #12644 are the tours that had no matches = did not kept any of the sequence 

no_perfect_match <- order_fin %>% 
  group_by(tourid) %>%
  filter(n_kept_order<100)

length(unique(no_perfect_match$tourid))#10534

#TOTAL 
12644+10534 #23178

```
#END#